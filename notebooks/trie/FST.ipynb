{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a9639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded words for input 'go': ['go']\n",
      "Decoded words for input 'fo': []\n",
      "Decoded words for input 'ghost': []\n"
     ]
    }
   ],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}  # Maps character to TrieNode\n",
    "        self.is_end_of_word = False  # Marks the end of a word\n",
    "\n",
    "class FSTTrie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"Insert a word into the trie.\"\"\"\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "    \n",
    "    def search(self, word):\n",
    "        \"\"\"Search for a word in the trie. Returns True if found.\"\"\"\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return node.is_end_of_word\n",
    "    \n",
    "    def starts_with(self, prefix):\n",
    "        \"\"\"Check if there exists any word with the given prefix.\"\"\"\n",
    "        node = self.root\n",
    "        for char in prefix:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return True\n",
    "    \n",
    "    def decode(self, input_sequence):\n",
    "        \"\"\"\n",
    "        Decode an input sequence of characters into valid words\n",
    "        by exploring all possible paths in the trie.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        node = self.root\n",
    "\n",
    "        def dfs(current_node, path, remaining_input):\n",
    "            if not remaining_input:  # If no input remains\n",
    "                if current_node.is_end_of_word:  # Check if this is a valid word\n",
    "                    results.append(\"\".join(path))\n",
    "                return\n",
    "\n",
    "            # Process the next character in the input\n",
    "            current_char = remaining_input[0]\n",
    "            if current_char in current_node.children:\n",
    "                # Follow the valid path\n",
    "                dfs(current_node.children[current_char], path + [current_char], remaining_input[1:])\n",
    "            \n",
    "            # Optionally handle blanks or mismatches (if needed)\n",
    "\n",
    "        dfs(node, [], input_sequence)\n",
    "        return results\n",
    "\n",
    "# Example Usage\n",
    "fst_trie = FSTTrie()\n",
    "lexicon = [\"go\", \"forth\", \"gone\"]\n",
    "\n",
    "# Insert words into the trie\n",
    "for word in lexicon:\n",
    "    fst_trie.insert(word)\n",
    "\n",
    "# Decode input sequences\n",
    "input_sequence = \"go\"  # Perfect match\n",
    "print(\"Decoded words for input 'go':\", fst_trie.decode(input_sequence))\n",
    "\n",
    "input_sequence = \"fo\"  # Partial match\n",
    "print(\"Decoded words for input 'fo':\", fst_trie.decode(input_sequence))\n",
    "\n",
    "input_sequence = \"ghost\"  # No match in lexicon\n",
    "print(\"Decoded words for input 'ghost':\", fst_trie.decode(input_sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f589908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to 'ghost': go\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(word1, word2):\n",
    "    \"\"\"Calculate the minimum edit distance between two words.\"\"\"\n",
    "    m, n = len(word1), len(word2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif word1[i - 1] == word2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "    return dp[m][n]\n",
    "\n",
    "def find_closest_word(trie, input_word):\n",
    "    \"\"\"Find the closest word in the trie to the input word based on edit distance.\"\"\"\n",
    "    closest_word = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for word in lexicon:\n",
    "        distance = edit_distance(input_word, word)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_word = word\n",
    "    \n",
    "    return closest_word\n",
    "\n",
    "# Example Usage\n",
    "print(\"Closest to 'ghost':\", find_closest_word(fst_trie, \"ghost\"))  # Expected output: 'gone' or 'go'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5da7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Search Results: [('gone', -1.0)]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "class FSTTrie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def beam_search(self, char_probs, beam_width=3):\n",
    "        \"\"\"\n",
    "        Perform beam search on the FST Trie with character probabilities.\n",
    "        \n",
    "        Args:\n",
    "            char_probs (list of dict): Each element is a dict of {char: prob}.\n",
    "            beam_width (int): The maximum number of candidates to retain at each step.\n",
    "        \n",
    "        Returns:\n",
    "            List of tuples: Decoded words and their scores.\n",
    "        \"\"\"\n",
    "        # Beam is a priority queue (negative score for max-heap behavior)\n",
    "        beam = [(0, self.root, [])]  # (score, current_node, path_so_far)\n",
    "\n",
    "        for timestep_probs in char_probs:\n",
    "            new_beam = []\n",
    "            for score, node, path in beam:\n",
    "                for char, prob in timestep_probs.items():\n",
    "                    if char in node.children:\n",
    "                        child_node = node.children[char]\n",
    "                        new_score = score + prob  # Add log-prob for beam pruning\n",
    "                        new_path = path + [char]\n",
    "                        heapq.heappush(new_beam, (new_score, child_node, new_path))\n",
    "            \n",
    "            # Keep only the top beam_width candidates\n",
    "            beam = heapq.nlargest(beam_width, new_beam)\n",
    "\n",
    "        # Extract complete words from the beam\n",
    "        results = []\n",
    "        for score, node, path in beam:\n",
    "            if node.is_end_of_word:\n",
    "                results.append((\"\".join(path), score))\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "fst_trie = FSTTrie()\n",
    "lexicon = [\"go\", \"gone\", \"forth\"]\n",
    "for word in lexicon:\n",
    "    fst_trie.insert(word)\n",
    "\n",
    "# Simulated LSTM output probabilities (at each timestep, char → log-probability)\n",
    "char_probs = [\n",
    "    {'g': -0.2, 'f': -1.0},   # Probabilities at timestep 1\n",
    "    {'o': -0.1, 'a': -1.2},   # Probabilities at timestep 2\n",
    "    {'n': -0.3, 'r': -1.5},   # Probabilities at timestep 3\n",
    "    {'e': -0.4, 't': -1.1},   # Probabilities at timestep 4\n",
    "]\n",
    "\n",
    "# Perform beam search\n",
    "results = fst_trie.beam_search(char_probs, beam_width=3)\n",
    "print(\"Beam Search Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da24e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTC Beam Search Results: [('go', -inf)]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_word = False\n",
    "\n",
    "class FSTTrie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def ctc_beam_search(self, char_probs, beam_width=3, blank='_'):\n",
    "        \"\"\"\n",
    "        Perform CTC beam search with FST constraints, and collapse repeated characters.\n",
    "        \n",
    "        Args:\n",
    "            char_probs (list of dict): Each element is a dict of {char: prob}.\n",
    "            beam_width (int): The maximum number of candidates to retain at each step.\n",
    "            blank (str): The blank symbol for CTC decoding.\n",
    "        \n",
    "        Returns:\n",
    "            List of tuples: Decoded words and their scores.\n",
    "        \"\"\"\n",
    "        # Beam is a priority queue (negative score for max-heap behavior)\n",
    "        beam = [(\"\", self.root, 0.0, None)]  # (prefix, current_node, score, last_char)\n",
    "\n",
    "        for timestep_probs in char_probs:\n",
    "            new_beam = defaultdict(lambda: (-float('inf'), -float('inf')))\n",
    "\n",
    "            for prefix, node, p_score, last_char in beam:\n",
    "                # Add blank symbol transition: Blank means skip this timestep\n",
    "                new_p_score = p_score + timestep_probs.get(blank, -float('inf'))\n",
    "                new_beam[(prefix, node)] = (\n",
    "                    max(new_beam[(prefix, node)][0], new_p_score),  # Update p_score for blank\n",
    "                    new_beam[(prefix, node)][1]  # Keep existing last_char\n",
    "                )\n",
    "\n",
    "                # Process each character (skip if it doesn't exist in the trie)\n",
    "                for char, prob in timestep_probs.items():\n",
    "                    if char == blank or char not in node.children:\n",
    "                        continue\n",
    "\n",
    "                    # Collapse repeated characters (skip adding if same as last_char)\n",
    "                    if char == last_char:\n",
    "                        continue\n",
    "                    \n",
    "                    child_node = node.children[char]\n",
    "                    new_prefix = prefix + char\n",
    "\n",
    "                    # Add probability for non-blank characters (non-repeating)\n",
    "                    new_p_score = p_score + prob\n",
    "                    new_beam[(new_prefix, child_node)] = (\n",
    "                        new_beam[(new_prefix, child_node)][0],  # Keep existing blank score\n",
    "                        max(new_beam[(new_prefix, child_node)][1], new_p_score)  # Update p_score for non-blank\n",
    "                    )\n",
    "\n",
    "            # Convert scores to log probabilities for ranking and limit beam size\n",
    "            beam = heapq.nlargest(\n",
    "                beam_width,\n",
    "                [(prefix, node, p_b, p_nb) for (prefix, node), (p_b, p_nb) in new_beam.items()],\n",
    "                key=lambda x: max(x[2], x[3])  # Use max of blank and non-blank probabilities\n",
    "            )\n",
    "\n",
    "        # Finalize by collapsing sequences and filtering valid words\n",
    "        results = []\n",
    "        for prefix, node, p_b, p_nb in beam:\n",
    "            if node.is_end_of_word:\n",
    "                results.append((prefix, max(p_b, p_nb)))\n",
    "        \n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "fst_trie = FSTTrie()\n",
    "lexicon = [\"go\", \"gone\", \"forth\"]\n",
    "for word in lexicon:\n",
    "    fst_trie.insert(word)\n",
    "\n",
    "# Simulated LSTM output probabilities (at each timestep, char → log-probability)\n",
    "char_probs = [\n",
    "    {'g': -0.2, 'f': -1.0, '_': -0.6},  # Timestep 1\n",
    "    {'o': -0.1, 'a': -1.2, '_': -0.4},  # Timestep 2\n",
    "    {'o': -0.3, 'r': -1.5, '_': -0.5},  # Timestep 3\n",
    "    {'n': -0.4, 't': -1.1, '_': -0.6},  # Timestep 4\n",
    "]\n",
    "\n",
    "# Perform beam search with CTC decoding\n",
    "results = fst_trie.ctc_beam_search(char_probs, beam_width=3)\n",
    "print(\"CTC Beam Search Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328e7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
